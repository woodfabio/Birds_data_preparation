# Birds_data_preparation
This project is composed by scripts in R and Python languages for Amazon birds vocalization data prepartion in 2D and 3D arrays.

As an undergraduate researcher at Ferraz Population Biology Lab (UFRGS) I helped to prepare vocalization data from 62 species of Amazon birds to posterior analysis of bayesian hierarquical modeling of population biology, obtaining estimatives like probabilities of presence, extinction, colonization and detection.

The raw dataset had informations like probability of detection of each species at each recording segment in CSV files and the posteior analysis required all this data organized in 2D and 3D arrays, separating the data, for example, by site, date and species. Besides, some sites names were not completely uniformized, with some letters capitalization not matching. To prepare the data we first developed R scripts to uniformize the letter capitalization and then prepare this data in organized arrays. However, this R script takes a very long time (about 2 days and a half) to complete the data preparation, and as we need to run this script many times (for example, using differend treshold values) I am currently working on translate this script to Python, which usually has a faster running than R (not ready year).

Attention to the fact that in this repository I am using only a small survey from the original dataset beacuse it is really huge (almost 700000 rows and 63 columns) only for demonstration purpose. This survey is composed by the last 2000 rows from the original dataset.

In this project we had to develop some scripts and create some files, listed by folder:

## Data_input
It has the original "raw" dataset files and also the versions of this dataset with uniformized letter capitalization:

1. **date_time_diurnal.txt**: the original CSV file with ID data from each recording segment. It has the following dimensions:
      - Rows: recording segments
      - Columns: ID data of each recording segment (site, date, recording number and segment number)

2. **date_time_diurnal_capitalization_python.txt**: the output from *segmts_and_sites_capitalization.py* (at the *Python_scipts* folder), which receives *date_time_diurnal.txt* as input and returns this file with uniformized letter capitalization. It is identical as *date_time_diurnal_capitalization_r.txt*, only generated through different languages.

3.  **date_time_diurnal_capitalization_r.txt**: the output from *segmts_and_sites_capitalization.R* (at the *R_scripts* folder), which receives *date_time_diurnal.txt* as input and returns this file with uniformized letter capitalization. It is identical as *date_time_diurnal_capitalization_python.txt*, only generated through different languages.

4.  **groups.csv**: a CSV file generated by the script *data_preparation_r.R* (at the *R_scripts* folder) with the groups names of each surveyed site. This file is used by the script *data_preparation_python.py* (at the *Python_scripts* folder).

5.  **locations_dirunal.txt**: the original CSV file with ID data from each site. It has the following dimensions:
     - Rows: sites
     - Columns: ID data of each site (name, forest type (old growth = 0, secondary forest = 1), geographic coordinates (X and Y))

6. **locations_diurnal_capitalization_python.txt**: the output from *segmts_and_sites_capitalization.py* (at the *Python_scipts* folder), which receives *locations_diurnal.txt* as input and returns this file with uniformized letter capitalization. It is identical as *locations_diurnal_capitalization_r.txt*, only generated through different languages.

7.  **locations_diurnal_capitalization_r.txt**: the output from *segmts_and_sites_capitalization.R* (at the *R_scripts* folder), which receives *locations_diurnal.txt* as input and returns this file with uniformized letter capitalization. It is identical as *locations_diurnal_capitalization_python.txt*, only generated through different languages.

8.  **shortY.csv**: the original CSV file where each cell has the probability of presence of the vocalization from that species in that segment. "shortY" is a small survey from the last 2000 rows from the original (much bigger) dataset. It has the following dimensions:
     - Rows: recording segments
     - Columns: species

## Python_scripts

## R_scripts


